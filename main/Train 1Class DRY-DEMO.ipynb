{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d586747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import copy\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from torch import cuda\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as tf\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.metrics.functional import accuracy as acc  \n",
    "\n",
    "import segmentationtraining as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d396042",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainFolder=\"./Data/trainData/A1234/\" #\"./Data/trainData/A1234/\"\n",
    "ValidFolder=\"./Data/trainData/Arundo4/\"  \n",
    "TestFolder=\"./Data/trainData/Arundo5/\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a6262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=48 #acceptable sizes on a 24GB GPU:  48 for 256x256 tiles and 16 for 512x512 tiles\n",
    "epochs=49  #looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f53d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.MAnet(\n",
    "    encoder_name=\"resnet152\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use None or `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2,                      # model output channels (number of classes in your dataset, add +1 for background)\n",
    "    # activation='softmax',  #deprecated for some models.  Last activation is self(x)\n",
    ")\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"device: \", device)\n",
    "\n",
    "\n",
    "#Net = model # Load net\n",
    "#Net=Net.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0232b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingLog=st.trainStart(model, TrainFolder, ValidFolder,epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingLog=st.trainFromLast(model, TrainFolder, ValidFolder,epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582bd3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59293df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plotTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56241443",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path=\"LOG for DeepLab-ENb7.csv\"\n",
    "st.validateCheckpoints(model,log_path,ValidFolder,batchSize=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3238b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
