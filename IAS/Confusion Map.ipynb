{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f010f42",
   "metadata": {},
   "source": [
    "# Confusion Map generation\n",
    "This is a tool to evaluate how well a trained model is doing.\n",
    "\n",
    "It generates a map where:\n",
    "True Negatives are marked Black\n",
    "True Positives are marked Green\n",
    "False Negatives are marked Blue\n",
    "False Positives are marked Red\n",
    "\n",
    "It also produces an Excel file with a confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d062234a",
   "metadata": {},
   "source": [
    " ## if evaluating a single class model\n",
    "\n",
    "**Ignore this if you're evaluating a multiclass model**\n",
    "\n",
    "Note that if evaluating a single class model:\n",
    " 1. you need to set *output_classes=2* in the next cell\n",
    " 1. also in the next cell specify the *single_class_species*. Default is 1 (Arundo) but refer to table below.\n",
    " 1. Selecting the species from the user interface will be disabled & set to 1. This is normal.\n",
    "A single class model only marks a 1 wherever the species it has been trained on is detected.  It doesn't know what that 1 refers to, so you have to specify what it (the single_class_species) is manually.  Failing to do so will fail to produce a correct confusion map. \n",
    "\n",
    "```\n",
    " 1 = Arundo\n",
    " 2 = Opuntia\n",
    " 3 =  Agricultural area  (not a species)\n",
    " 4 = Eucalyptus\n",
    " 5 = Agave\n",
    " 6= Acacia\n",
    " 7 = Prinjol(Pines)  (not included in training during the project so it's intended only for future models)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec025a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many classes the model can output\n",
    "# 1 for background + number of species/classes detectable.\n",
    "# Multiclass models coming out of the project had  output_classes=7 \n",
    "output_classes=2\n",
    "single_class_species= 5    # this is ignored in multi-class mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922686af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only change this if you have trained for more classes than listed.\n",
    "\n",
    "species_available=[1,2,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a93f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,50).__str__()\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import visualisations2 as vis2\n",
    "import gc\n",
    "from torch import cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29909fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet152\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use None or `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=output_classes,                      # model output channels (number of classes in your dataset, add +1 for background)\n",
    "    activation='softmax',  #deprecated for some models.  Last activation is self(x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aee7d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "Net=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "044d36b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff253b5a8b4841769ddfea3f21a25c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Pick Model:', options=('UnetPlusPlus-ResNetEnc-1048-12-7-2023',), rows=10, value='UnetPlusâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f7e964324e45028985cbc59a6cafd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Accept & Proceed', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Model=''\n",
    "ModelPath=''\n",
    "epochs=[]\n",
    "epochNums=[]\n",
    "speciesList=[]\n",
    "saveString=''\n",
    "\n",
    "disable_species_selection=False\n",
    "if output_classes <= 2:  # in case of a single-class model\n",
    "    output_classes = 2\n",
    "    vis2.single_class_mode = True  # if false, detection operates on Multiclass\n",
    "    vis2.single_class =single_class_species   # if operating on single class this is the class being detected\n",
    "    species_available=[single_class_species]\n",
    "    disable_species_selection=True\n",
    "\n",
    "def create_dir(path):\n",
    "\t\"\"\" To creating a directory if it does not exist\"\"\"\n",
    "\tif not os.path.exists(path): os.makedirs(path)\n",
    "\n",
    "\n",
    "def FinalOptions():\n",
    "    global saveString\n",
    "    global AcceptEpochsButton\n",
    "    AcceptEpochsButton.close()\n",
    "    \n",
    "    saveString='./Results/'+Model+'/'\n",
    "    create_dir(saveString)\n",
    "    global species_available\n",
    "    global disable_species_selection\n",
    "    Speciesbox = widgets.SelectMultiple(options=species_available,\n",
    "        value=[species_available[0]],\n",
    "        rows=6,\n",
    "        description='Choose species to detect:',\n",
    "        disabled=disable_species_selection)\n",
    "    \n",
    "    ListRasters = os.listdir(\".\\\\Data\\\\source\\\\labels\")\n",
    "    for i in ListRasters:\n",
    "        if not os.path.isfile(\".\\\\Data\\\\source\\\\labels\\\\\"+i):\n",
    "            ListRasters.remove(i)\n",
    "    Rasterbox = widgets.SelectMultiple(\n",
    "        options=ListRasters,\n",
    "        value=[ListRasters[0]],\n",
    "        rows=12,\n",
    "        description='Select Rasters:',\n",
    "        disabled=False)\n",
    "    Tilebox = widgets.IntText(value=1600, description='Tile Size:', disabled=False)\n",
    "    \n",
    "    Execute = widgets.Button(description='Process', disabled=False,button_style='')\n",
    "        \n",
    "    def ProduceResults(b):\n",
    "        global speciesList\n",
    "        global Model\n",
    "        global ModelPath\n",
    "        global epochs\n",
    "        global epochNums\n",
    "        global speciesList\n",
    "        global saveString\n",
    "        \n",
    "        speciesList=Speciesbox.value\n",
    "        rasters=Rasterbox.value\n",
    "        tile_size=Tilebox.value\n",
    "        print(\"Rasters:\", rasters, \"  Species:\",speciesList, \"Tile Size=\",tile_size)\n",
    "        Speciesbox.close()\n",
    "        Rasterbox.close()\n",
    "        Tilebox.close()\n",
    "        Execute.close()\n",
    "        \n",
    "        for i in range(len(epochNums)):\n",
    "    \n",
    "            epoch=epochs[i]\n",
    "            epoch_num=epochNums[i]\n",
    "            Net.load_state_dict(torch.load(epoch))\n",
    "            for raster in rasters:\n",
    "                image_file_path=\".\\\\Data\\\\source\\\\rasters\\\\\"+raster \n",
    "                label_file_path=\".\\\\Data\\\\source\\\\labels\\\\\"+raster \n",
    "                save_as=saveString+raster[:-4]+'-Ep'+str(epoch_num)\n",
    "                RawPrediction, Lbl=vis2.GeneratePredictionWithLabel(Net, image_file_path,label_file_path, tilesize=tile_size, save_name=None)\n",
    "                df,ArgmaxMap=vis2.Pred2Result(RawPrediction, Lbl, save_as)\n",
    "                del RawPrediction\n",
    "                gc.collect()\n",
    "                cuda.empty_cache()\n",
    "                #ArgmaxMap=ArgmaxMapOnly(Net, image_file_path, tilesize=1600, save_name=None)\n",
    "                for s in speciesList:\n",
    "                    vis2.Argmax2ConfMap(ArgmaxMap,Lbl,save_as,species=s)\n",
    "                    print(s, \"saved\")\n",
    "        \n",
    "    \n",
    "    Execute.on_click(ProduceResults)\n",
    "\n",
    "    display(Rasterbox, Speciesbox, Tilebox, Execute)\n",
    "    \n",
    "    \n",
    "\n",
    "def processModel():\n",
    "    AcceptModel.close()\n",
    "    global AcceptEpochsButton\n",
    "    AcceptEpochsButton = widgets.Button(description='Accept & Proceed', disabled=False,button_style='')\n",
    "    ListEpochs = []\n",
    "    for file in os.listdir(ModelPath):\n",
    "        if file[-6:]=='.torch':\n",
    "            ListEpochs.append(file)\n",
    "\n",
    "    Epochsbox= widgets.SelectMultiple(options=ListEpochs,\n",
    "        value=[ListEpochs[0]],\n",
    "        rows=15,\n",
    "        description='Epochs:',\n",
    "        disabled=False)\n",
    "\n",
    "    def AcceptEpochs(b):\n",
    "        global epochs\n",
    "        global epochNums\n",
    "        global ModelPath\n",
    "        global Model\n",
    "        \n",
    "        for i in range(len(Epochsbox.value)):\n",
    "            epochs.append(ModelPath+Epochsbox.value[i])\n",
    "        for i in range(len(epochs)):\n",
    "            epochNums.append(epochs[i].split('/')[-1].split('-')[0])\n",
    "\n",
    "        Epochsbox.close()\n",
    "        Suggestionbox.close()\n",
    "        row1.close()\n",
    "        print(\"Epochs: \", epochs )\n",
    "        AcceptEpochsButton.close()\n",
    "        FinalOptions()\n",
    "        return\n",
    " \n",
    "    AcceptEpochsButton.on_click(AcceptEpochs)\n",
    "    \n",
    "    #===================================================\n",
    "    log_path='.\\\\Models\\\\'+Model+'\\\\'+\"Log for MC-\"+Model+'.csv'\n",
    "    best_epochs_suggestion='Suggested Epochs: '\n",
    "    for i in vis2.FindBestEpochs(log_path):\n",
    "        best_epochs_suggestion=best_epochs_suggestion+str(i)+', '\n",
    "    best_epochs_suggestion=best_epochs_suggestion[0:-2]\n",
    "    Suggestionbox=widgets.Label(best_epochs_suggestion)\n",
    "    \n",
    "    row1=widgets.HBox([Epochsbox,Suggestionbox])\n",
    "    display(row1, AcceptEpochsButton)\n",
    "\n",
    "\n",
    "\n",
    "ListModels = []\n",
    "for file in os.listdir(\".\\\\Models\\\\\"):\n",
    "    d = os.path.join(\".\\\\Models\\\\\", file)\n",
    "    if os.path.isdir(d):\n",
    "        ListModels.append(file)\n",
    "if '_usable' in ListModels: ListModels.remove('_usable')\n",
    "\n",
    "Modelsbox = widgets.Select(\n",
    "    options=ListModels,\n",
    "    value=ListModels[0],\n",
    "    rows=10,\n",
    "    description='Pick Model:',\n",
    "    disabled=False)\n",
    "\n",
    "AcceptModel = widgets.Button(description='Accept & Proceed', disabled=False,button_style='')\n",
    "\n",
    "def GetModel(b):\n",
    "    global Model\n",
    "    global ModelPath\n",
    "    Model=Modelsbox.value\n",
    "    ModelPath='./Models/'+ Model +'/'\n",
    "    Modelsbox.close()\n",
    "    print(\"Model: \", Model )\n",
    "    processModel()\n",
    "    return\n",
    " \n",
    "        \n",
    "AcceptModel.on_click(GetModel)\n",
    "\n",
    "display(Modelsbox, AcceptModel)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1da854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb359e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis2.single_class_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdf4a266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis2.single_class_species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19600af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
